# Ollama HTTP endpoint
OLLAMA_BASE_URL=http://localhost:11434

# Generation model (must be pulled in Ollama)
GEN_MODEL=llama3.2:3b

# Embedding model (must be pulled in Ollama)
EMB_MODEL=nomic-embed-text

# Retrieval settings
CHUNK_SIZE=1200
CHUNK_OVERLAP=200
TOP_K=5
SIM_THRESHOLD=0.30
PORT=3000